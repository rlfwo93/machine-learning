{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0_for_beginner",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlfwo93/machine-learning/blob/master/TF2_0_for_beginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "And-bzjjMM3i"
      },
      "source": [
        "# Tensorflow library import하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYB7HIyUMRBU",
        "outputId": "e41e6f25-eb32-4f66-f824-d1f14861a5f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 380.5MB 38kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 35.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 46.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq15enbJMVUx"
      },
      "source": [
        "# MNIST dataset 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8baI-l5MxdU"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwL4E9_YNedG"
      },
      "source": [
        "## 왜 255.0으로 나눠주는 거지?\n",
        "mnist.load_data()로 불러온 데이터들은 모두 정수형이다.\n",
        "0 ~ 255사이의 값을 255.0으로 나눠주면 0 ~ 1사이 값으로 바뀌게된다. 이것을 정규화(normalization)이라고 한다.\n",
        "\n",
        "## 왜 정규화가 필요해?\n",
        "정규화는 feature들의 값을 왜곡하지 않고 scale을 공통적으로 변경시키는 것을 말하며 feature scaling이라고도 한다.\n",
        "\n",
        "0 ~ 1 사이 값으로 데이터들이 정규화되면 Gradient Descent를 수행할 때 unnormalized data를 사용할 때보다 더 쉽고 빠르게 수행하여 optimum 지점에 가까워지게 된다.\n",
        "\n",
        "**즉 학습이 잘되기 때문에 정규화를 하는 것이다.**\n",
        "\n",
        "정규화의 일반적인 방법은 다음과 같다.\n",
        "$$\n",
        "    \\frac{x-x_{min}}{x_{max}-x_{min}}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-1UIHXoPU4g"
      },
      "source": [
        "# 모델을 만들자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh9OcOosNTSu"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWypdoJ-P2Js"
      },
      "source": [
        "## model 구조\n",
        "모델에 사용된 레이어들\n",
        "* flatten : 1d로 평평하게 펴주는 레이어\n",
        "* Dense : fully connected 레이어. 이전 레이어의 출력과 모든 뉴런들을 연결한다.\n",
        "* Dropout : regularization을 위해 사용하는 Dropout, 특정 비율로 뉴런을 turn off해서 학습한다.\n",
        "\n",
        "1. Flatten(input_shape=(28,28)) : 28x28 shape의 입력데이터를 28*28 x 1로 변경해준다.\n",
        "2. Dense(128, activation='relu') : 128개의 뉴런을 가진 FC layer, 활성함수는 relu를 사용한다.\n",
        "3. Dropout(0.2) : 20%의 뉴런을 drop한다.\n",
        "4. Dense(10, activation='softmax') : 10개의 뉴런을 가진 FC layer, 활성함수는 softmax를 사용한다.\n",
        "\n",
        "output layer의 뉴런이 10개이고 softmax를 활성화함수로 사용한 것으로 보아 10개의 class에 대한 확률 벡터를 출력할 것이다.\n",
        "\n",
        "compile() 메소드를 사용해서 optimizer, loss, metrics을 설정한다.\n",
        "\n",
        "### optimizer\n",
        "optimizer로는 adam을 사용한다.\n",
        "\n",
        "tf.keras.optimizers에서 지원하고 있는 optimizer를 사용할 수 있다.\n",
        "\n",
        "### loss\n",
        "loss(손실함수)로는 sparse_categorical_crossentropy를 사용한다.\n",
        "\n",
        "tf.losses에서 제공하는 함수를 사용할 수 있다.\n",
        "\n",
        "만약 output이 여러개라면 loss의 리스트나 딕셔너리를 넘겨줌으로써 각각 다른 loss를 사용할 수 있다.\n",
        "\n",
        "loss 값은 각 loss들의 합에 의해서 최소화된다.\n",
        "\n",
        "### metrics\n",
        "metrics은 accuracy를 사용한다.\n",
        "\n",
        "학습과 테스트 과정에서 평가로 사용할 metric의 list를 전달해줘야한다. 일반적으로 ['accuracy']를 사용한다.\n",
        "\n",
        "`metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`\n",
        "이런식으로 사용하기도 한다.\n",
        "\n",
        "그 외의 다양한 매개변수에 대한 정보는 \n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n",
        "를 참고하자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU1xU9P7S-JQ",
        "outputId": "8b48844c-2d47-4747-ff59-1671c5d4f97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2953 - acc: 0.9136\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1440 - acc: 0.9570\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1068 - acc: 0.9674\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0886 - acc: 0.9721\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0765 - acc: 0.9764\n",
            "10000/10000 - 0s - loss: 0.0722 - acc: 0.9782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07215387922241352, 0.9782]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivfR-H6ETM2Q"
      },
      "source": [
        "# 모델 훈련과 평가\n",
        "\n",
        "**이 예제에서는 5회 반복하여 train data 6만개를 학습한다.**\n",
        "\n",
        "**평가 단계에서는 test 데이터 10000개를 사용했다.**\n",
        "\n",
        "**loss값이 0.0722 이고 예측 정확도가 97.8%인 모델이 학습되었음을 확인할 수 있다.**\n",
        "\n",
        "\n",
        "\n",
        "model.fit() - 고정된 epochs 수만큼 모델을 학습한다.\n",
        "```python\n",
        "fit(\n",
        "    x=None,\n",
        "    y=None,\n",
        "    batch_size=None,\n",
        "    epochs=1,\n",
        "    verbose=1,\n",
        "    callbacks=None,\n",
        "    validation_split=0.0,\n",
        "    validation_data=None,\n",
        "    shuffle=True,\n",
        "    class_weight=None,\n",
        "    sample_weight=None,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    validation_freq=1,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False,\n",
        "    **kwargs\n",
        ")\n",
        "```\n",
        "x : input data(주로 numpy array, tf tensor)\n",
        "\n",
        "y : target data(주로 numpy array, tf tensor)\n",
        "\n",
        "batch_size : 사용하게 되면 디폴트 값 32. train data를 32개의 배치로 구분한다.\n",
        "\n",
        "epochs = 모델을 학습할 횟수.\n",
        "\n",
        "verbose = 학습과정을 어떻게 보여줄 것인지.\n",
        "0 : 아무것도 표시 안함.\n",
        "1 : progress bar\n",
        "2 : 각 epoch마다 one line 표시\n",
        "\n",
        "이 외의 매개변수는 API 확인\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
        "\n",
        "model.evaluate() - test 모드에서 모델의 지정해줬던 metrics 값과 loss 값을 반환한다.\n",
        "\n",
        "```python\n",
        "evaluate(\n",
        "    x=None,\n",
        "    y=None,\n",
        "    batch_size=None,\n",
        "    verbose=1,\n",
        "    sample_weight=None,\n",
        "    steps=None,\n",
        "    callbacks=None,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False\n",
        ")\n",
        "```\n",
        "\n",
        "fit()에서의 파라미터들과 동일한 기능을 한다.\n"
      ]
    }
  ]
}